{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "from keras.layers import Embedding, \\\n",
    "    Input, \\\n",
    "    Dense, \\\n",
    "    Flatten, \\\n",
    "    merge, \\\n",
    "    SimpleRNN, \\\n",
    "    TimeDistributed\n",
    "from keras.models import Model, \\\n",
    "    Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corpus length:', 600901)\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "chars.insert(0, \"\\0\")\n",
    "chars_idx = {char:idx for idx, char in enumerate(chars)}\n",
    "idx_chars = {idx:char for idx, char in enumerate(chars)}\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs = 4\n",
    "char_1 = [chars_idx[text[i]] for i in range(0, len(text) - cs - 1, cs)]\n",
    "char_2 = [chars_idx[text[i + 1]] for i in range(1, len(text) - cs - 1, cs)]\n",
    "char_3 = [chars_idx[text[i + 2]] for i in range(1, len(text) - cs - 1, cs)]\n",
    "char_4 = [chars_idx[text[i + 3]] for i in range(1, len(text) - cs - 1, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(char_1)\n",
    "x2 = np.stack(char_2)\n",
    "x3 = np.stack(char_3)\n",
    "y = np.stack(char_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next char from 3 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name):\n",
    "    x_in = Input(shape=(1,), name=name)\n",
    "    x_emb = Embedding(input_dim=vocab_size, output_dim=n_fac, input_length=1)(x_in)\n",
    "    return x_in, Flatten()(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1_in, x1_emb = embedding_input('char1')\n",
    "x2_in, x2_emb = embedding_input('char2')\n",
    "x3_in, x3_emb = embedding_input('char3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(256, activation='tanh')\n",
    "dense_hidden = Dense(256, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c1_hidden = dense_in(x1_emb)\n",
    "hidden_2 = dense_hidden(c1_hidden)\n",
    "c2_dense = dense_in(x2_emb)\n",
    "c2_hidden = merge([hidden_2, c2_dense])\n",
    "hidden_3 = dense_hidden(c2_hidden)\n",
    "c3_dense = dense_in(x3_emb)\n",
    "c3_hidden = merge([hidden_3, c3_dense])\n",
    "c4_out = Dense(vocab_size, activation='softmax')((c3_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model([x1_in, x2_in, x3_in], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "char1 (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "char2 (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "char3 (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)         (None, 1, 42)         3612        char1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "embedding_14 (Embedding)         (None, 1, 42)         3612        char2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "embedding_15 (Embedding)         (None, 1, 42)         3612        char3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 42)            0           embedding_13[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 42)            0           embedding_14[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 42)            0           embedding_15[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_15 (Dense)                 (None, 256)           11008       flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_16 (Dense)                 (None, 256)           65792       dense_15[0][0]                   \n",
      "                                                                   merge_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_12 (Merge)                 (None, 256)           0           dense_16[0][0]                   \n",
      "                                                                   dense_15[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_13 (Merge)                 (None, 256)           0           dense_16[1][0]                   \n",
      "                                                                   dense_15[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_17 (Dense)                 (None, 86)            22102       merge_13[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 109,738\n",
      "Trainable params: 109,738\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150224/150224 [==============================] - 13s - loss: 3.5734    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d489be150>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, nb_epoch=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next char from previous n chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_prev_chars = 8\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_in_list = [[chars_idx[text[cs + i]] for i in range(num_prev_chars)] for cs in range(len(text) - num_prev_chars)]\n",
    "y_list = [chars_idx[text[i]] for i in range(num_prev_chars, len(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_in = np.stack(c_in_list)\n",
    "y = np.stack(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chk = [c_in[:, col_num] for col_num in range(c_in.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='tanh', init='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = []\n",
    "emb = []\n",
    "for char_num in range(num_prev_chars):\n",
    "    ci_in, ci_emb = embedding_input('char_' + str(char_num + 1))\n",
    "    inp.append(ci_in)\n",
    "    emb.append(ci_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ci_dense = num_prev_chars*[None]\n",
    "ci_hidden = num_prev_chars*[None]\n",
    "ci_hidden_inp = num_prev_chars*[None]\n",
    "ci_hidden[0] = dense_in(emb[0])\n",
    "for char_num in range(1, num_prev_chars):\n",
    "    ci_dense[char_num] = dense_in(emb[char_num])\n",
    "    ci_hidden_inp[char_num] = dense_hidden(ci_hidden[char_num - 1])\n",
    "    ci_hidden[char_num] = merge([ci_dense[char_num], ci_hidden_inp[char_num]])\n",
    "c_out = dense_out(ci_hidden[num_prev_chars - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inp, c_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600893/600893 [==============================] - 181s - loss: 2.2627   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d2492c2d0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(chk, y, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac, vocab_size, n_hidden, num_prev_chars = (42, vocab_size, 256, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(input_dim=vocab_size, output_dim=n_fac, input_length=num_prev_chars),\n",
    "                    SimpleRNN(n_hidden),\n",
    "                    Dense(vocab_size, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600893/600893 [==============================] - 118s - loss: 1.9988   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d250c5d50>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(c_in, y, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_keras(inp):\n",
    "    idxs = [chars_idx[c] for c in inp]\n",
    "    arrs = np.array(idxs)[np.newaxis,:]\n",
    "    p = model.predict(arrs)[0]\n",
    "    return idx_chars[np.argmax(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_keras('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Sequences in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac, vocab_size, n_hidden, num_prev_chars = (42, vocab_size, 256, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_in_seq = c_in[:(c_in.shape[0] - 1)]\n",
    "c_out_seq = np.atleast_3d(c_in[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential([Embedding(input_dim=vocab_size, output_dim=n_fac, input_length=num_prev_chars),\n",
    "                    SimpleRNN(n_hidden, activation='tanh', inner_init='identity', return_sequences=True),\n",
    "                    TimeDistributed(Dense(vocab_size, activation='softmax'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_72 (Embedding)         (None, 8, 42)         3612        embedding_input_6[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "simplernn_6 (SimpleRNN)          (None, 8, 256)        76544       embedding_72[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_4 (TimeDistribut (None, 8, 86)         22102       simplernn_6[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 102,258\n",
      "Trainable params: 102,258\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600892/600892 [==============================] - 66s - loss: 1.9705    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8cff931f90>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(c_in_seq, c_out_seq, nb_epoch=1, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
